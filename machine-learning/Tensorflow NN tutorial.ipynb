{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev2\"><a href=\"#Multilayer-Convolutional-Network\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Multilayer Convolutional Network</a></div><div class=\"lev2\"><a href=\"#Convolution-and-Pooling\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Convolution and Pooling</a></div><div class=\"lev2\"><a href=\"#First-Convolutional-Layer\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>First Convolutional Layer</a></div><div class=\"lev2\"><a href=\"#second-layer\"><span class=\"toc-item-num\">0.4&nbsp;&nbsp;</span>second layer</a></div><div class=\"lev2\"><a href=\"#Densely-Connected-Layer\"><span class=\"toc-item-num\">0.5&nbsp;&nbsp;</span>Densely Connected Layer</a></div><div class=\"lev2\"><a href=\"#dropout\"><span class=\"toc-item-num\">0.6&nbsp;&nbsp;</span>dropout</a></div><div class=\"lev2\"><a href=\"#readout-layer\"><span class=\"toc-item-num\">0.7&nbsp;&nbsp;</span>readout layer</a></div><div class=\"lev2\"><a href=\"#train-and-evaluate-the-model\"><span class=\"toc-item-num\">0.8&nbsp;&nbsp;</span>train and evaluate the model</a></div><div class=\"lev2\"><a href=\"#最適化の方法について\"><span class=\"toc-item-num\">0.9&nbsp;&nbsp;</span>最適化の方法について</a></div><div class=\"lev3\"><a href=\"#steepeset-gradient-descent-optimize\"><span class=\"toc-item-num\">0.9.1&nbsp;&nbsp;</span>steepeset gradient descent optimize</a></div><div class=\"lev3\"><a href=\"#ADAM-optimzer\"><span class=\"toc-item-num\">0.9.2&nbsp;&nbsp;</span>ADAM optimzer</a></div><div class=\"lev2\"><a href=\"#Sthochastic-Grdient-Descent(SGD)\"><span class=\"toc-item-num\">0.10&nbsp;&nbsp;</span>Sthochastic Grdient Descent(SGD)</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmaxの復習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "for i in range(1000):\n",
    "  batch = mnist.train.next_batch(100)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9192\n",
      "Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "print(cross_entropy)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Convolutional Network\n",
    "ReLU neuron:\n",
    "\n",
    "rectifier : 活性関数\n",
    "\n",
    "$f(x)=\\max(0,x)$\n",
    "\n",
    "シグモイドやハイパボリックタンジェントよりも生物学的にも妥当で性能がいいとされる。この活性関数を使ったユニットをrectified linear unit(ReLU)と呼ぶ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution and Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Convolutional Layer\n",
    "畳み込みは5x5のパッチから32の特徴量を計算、最初の二次元がパッチサイズ、次がチャネル数、最後が出力数としてつくる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この層をあてるには、入力xを4次元のテンソルにする必要がある。2,3次元めが縦と横、4次元めは色のチャネル数、1次元めは？？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "畳み込んで、バイアスを足して、ReLU関数をあて、max poolする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool:0' shape=(?, 14, 14, 32) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_pool1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 28, 28, 32) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## second layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "イメージとしては32枚の特徴量画像（14x14ピクセル)に対してさらにもう一回畳み込みをする。なので3次元目(入力チャネル数)は32。そこから64チャネルつくる。\n",
    "\n",
    "出力チャネル数は入力チャネルの定数倍じゃなくても大丈夫なの？->たぶん大丈夫。5x5x32に対していくつ出力するのかという話なだけだと思う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2)  + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Densely Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "イメージサイズは7x7、64チャネルになった。\n",
    "\n",
    "これを一列に並べて、全結合させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024]) \n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dropout\n",
    "オーバーフィッティングをさけるためにドロップアウトを適用する。\n",
    "\n",
    "トレーニングのときはドロップアウトをオン、テストのときはオフにするために、placeholderを使う。\n",
    "\n",
    "ドロップアウト(2014): コネクション、ユニットそれぞれ確率pでオフにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## readout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train and evaluate the model\n",
    "ソフトマックスのときと違うこと：\n",
    "\n",
    "1. steepeset gradient descent optimize -> ADAM optimzer\n",
    "2. ドロップアウトのパラメーターを追加\n",
    "3. ログ出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_6:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.12\n",
      "step 100, training accuracy 0.86\n",
      "step 200, training accuracy 0.88\n",
      "step 300, training accuracy 0.94\n",
      "step 400, training accuracy 0.96\n",
      "step 500, training accuracy 0.88\n",
      "step 600, training accuracy 0.94\n",
      "step 700, training accuracy 0.98\n",
      "step 800, training accuracy 0.96\n",
      "step 900, training accuracy 0.96\n",
      "step 1000, training accuracy 1\n",
      "step 1100, training accuracy 0.98\n",
      "step 1200, training accuracy 0.98\n",
      "step 1300, training accuracy 0.96\n",
      "step 1400, training accuracy 0.94\n",
      "step 1500, training accuracy 0.94\n",
      "step 1600, training accuracy 0.94\n",
      "step 1700, training accuracy 0.92\n",
      "step 1800, training accuracy 0.96\n",
      "step 1900, training accuracy 1\n",
      "test accuracy 0.9773\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(2000):\n",
    "    batch  = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_:batch[1], keep_prob:1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy) )\n",
    "    train_step.run(feed_dict={x:batch[0], y_:batch[1], keep_prob:0.5})\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x:mnist.test.images, y_:mnist.test.labels, keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化の方法について\n",
    "### steepeset gradient descent optimize \n",
    "基本的なアイデア：いまいる点にたいして導関数を計算して、それにプロポーショナルに移動すればよい\n",
    "\n",
    "### ADAM optimzer\n",
    "\n",
    "## Sthochastic Grdient Descent(SGD)\n",
    "確率的降下法\n",
    "\n",
    "\n",
    "\n",
    "https://ja.scribd.com/doc/260859670/30minutes-Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
